import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test_public.csv')

train_data = train_data[train_data['MISSING_DATA'] == False]

# Data preprocessing
def polyline_to_trip_duration(polyline):
  return max(polyline.count("[") - 1, 0) * 15

train_data['TRAVEL_TIME'] = train_data["POLYLINE"].apply(polyline_to_trip_duration)

types = {'A': 0, 'B': 1, 'C': 2}
train_data['CALL_TYPE'] = train_data['CALL_TYPE'].map(types)
train_data['DAY_TYPE'] = train_data['DAY_TYPE'].map(types)
test_data['CALL_TYPE'] = test_data['CALL_TYPE'].map(types)
test_data['DAY_TYPE'] = test_data['DAY_TYPE'].map(types)

# Define dataset for train_data
class CustomDataset(Dataset):
    def __init__(self, data):
        self.x = data[['CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TIMESTAMP', 'DAY_TYPE']].values
        self.y = data['TRAVEL_TIME'].values

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]

# Create dataset and data loader
train_data = train_data.fillna(0)
test_data = test_data.fillna(0)

train_dataset = CustomDataset(train_data)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

class Model(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(Model, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.bn = nn.BatchNorm1d(hidden_size)
        self.dropout = nn.Dropout(0.95)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        batch_size = x.size(0)
        seq_len = x.size(1)
        x = x.unsqueeze(-1)
        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, dtype=x.dtype).to(x.device)
        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, dtype=x.dtype).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.bn(out[:, -1, :])
        out = self.dropout(out)
        out = self.fc(out)
        return out
torch.autograd.set_detect_anomaly(True)
from torch.optim.lr_scheduler import ExponentialLR

input_size = 1
hidden_size = 64
num_layers = 3
output_size = 1
num_epochs = 30
learning_rate = 0.01

model = Model(input_size, hidden_size, num_layers, output_size).to(device)
loss_fn = nn.MSELoss().to(device)
optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)
scheduler = ExponentialLR(optimizer, gamma=0.9)

# Training
model.train()
for epoch in range(num_epochs):
    total_loss = 0
    num_batches = 0

    for x, y in train_loader:
        x = x.to(device)
        y = y.to(device)

        optimizer.zero_grad()
        y_pred = model(x.float())
        loss = loss_fn(y_pred.squeeze(), y.float())
        loss.backward()
        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        total_loss += loss.item()
        num_batches += 1

    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {total_loss / num_batches}')
    scheduler.step()
    
#Define dataset for test_data
class TestDataset(Dataset):
    def __init__(self, data):
        self.x = data[['CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TIMESTAMP', 'DAY_TYPE']].values

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx]

test_dataset = TestDataset(test_data)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

#Save predictions
predictions = []
model.eval()
with torch.no_grad():
    for x in test_loader:
        x = x.to(device)
        outputs = model(x.float())
        predictions.append(outputs.detach().cpu().numpy())

predictions = np.concatenate(predictions)

# Save predictions to a CSV file
test_data['TRAVEL_TIME'] = predictions
test_data['TRIP_ID'] = test_data['TRIP_ID'].astype(str)
test_data[['TRIP_ID', 'TRAVEL_TIME']].to_csv('predictions.csv', index=False)

#get final weights
final_weights = model.state_dict()
torch.save(final_weights, 'final_weights.pth')
with open('final_weights.txt', 'w') as f:
    print(final_weights, file=f)
